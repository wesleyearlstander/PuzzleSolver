{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Images: 100%|██████████| 48/48 [00:01<00:00, 26.19it/s]\n",
      "Loading Masks: 100%|██████████| 48/48 [00:00<00:00, 200.82it/s]\n",
      "Resizing Images: 100%|██████████| 48/48 [00:00<00:00, 3314.95it/s]\n",
      "Resizing Masks: 100%|██████████| 48/48 [00:00<00:00, 7443.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (768, 1024, 3) -> (192, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from classes import *\n",
    "from Baseline import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Pieces: 48it [00:10,  4.59it/s]\n"
     ]
    }
   ],
   "source": [
    "pieces = np.array(Puzzle(MATCH_IMGS).pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get test and train features\n",
    "def get_DoG_train(pieces):\n",
    "    foreground = []\n",
    "    background = []\n",
    "    for p in pieces:\n",
    "        foreground.append(np.concatenate([p.RGB_foreground, p.DoG_foreground], axis = 1))\n",
    "        background.append(np.concatenate([p.RGB_background, p.DoG_background], axis = 1 ))\n",
    "    foreground = np.concatenate(foreground)\n",
    "    background = np.concatenate(background)\n",
    "    \n",
    "    return foreground, background\n",
    "  \n",
    "def get_DoG_test(pieces):\n",
    "    X_test = []\n",
    "    msks = []\n",
    "    for p in pieces:\n",
    "        X_test.append(np.concatenate([p.features_RGB, p.features_DoG], axis = 1))\n",
    "        msks.append(p.mask.flatten())\n",
    "    return np.concatenate(X_test), np.concatenate(msks)\n",
    "\n",
    "def get_RGB_train(pieces):\n",
    "    foreground = []\n",
    "    background = []\n",
    "    for p in pieces:\n",
    "        foreground.append(p.RGB_foreground)\n",
    "        background.append(p.RGB_background)\n",
    "    foreground = np.concatenate(foreground)\n",
    "    background = np.concatenate(background)\n",
    "    \n",
    "    return foreground, background\n",
    "\n",
    "def get_RGB_test(pieces):\n",
    "    X_test = []\n",
    "    msks = []\n",
    "    for p in pieces:\n",
    "        X_test.append(p.features_RGB)\n",
    "        msks.append(p.mask.flatten())\n",
    "    return np.concatenate(X_test), np.concatenate(msks)\n",
    "\n",
    "\n",
    "def get_MR8_train(pieces):\n",
    "    foreground = []\n",
    "    background = []\n",
    "    for p in pieces:\n",
    "        foreground.append(p.MR8_foreground)\n",
    "        background.append(p.MR8_background)\n",
    "    foreground = np.concatenate(foreground)\n",
    "    background = np.concatenate(background)\n",
    "    \n",
    "    return foreground, background\n",
    "\n",
    "    \n",
    "def get_MR8_test(pieces):\n",
    "    X_test = []\n",
    "    msks = []\n",
    "    for p in pieces:\n",
    "        X_test.append(p.features_MR8)\n",
    "        msks.append(p.mask.flatten())\n",
    "    return np.concatenate(X_test), np.concatenate(msks)\n",
    "\n",
    "#Check if predictions make sense\n",
    "def plot_prob(height = 192, width = 256, p = None, k= 0 ):\n",
    "    plt.imshow(p[k*height*width:(k+1)*height*width].reshape(height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pieces[:40]\n",
    "test = pieces[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train foreground and background model\n",
    "foreground_RGB, background_RGB = get_MR8_train(train)\n",
    "X_RGB, y = get_MR8_test(test)\n",
    "Model_RGB = Baseline()\n",
    "Model_RGB.fit(foreground_RGB)\n",
    "RGBF_pred = Model_RGB.predict(X_RGB)\n",
    "Model_RGB.fit(background_RGB)\n",
    "RGBB_pred = Model_RGB.predict(X_RGB)\n",
    "l = len(foreground_RGB) / ( len(foreground_RGB) + len(background_RGB) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(features_Train = None, features_Test = None,  threshold = 0.5, k = 6, pieces = None):\n",
    "    \"\"\"\n",
    "    features_Train : Function to extract train features\n",
    "    features_Test: Function to extract test features\n",
    "    \"\"\"\n",
    "    kfold = KFold(6)\n",
    "    scores = []\n",
    "    for train, test in kfold.split(pieces):\n",
    "        foreground, background = features_Train(pieces[train])\n",
    "        X, y = features_Test(pieces[test])\n",
    "        Base_model = Baseline()\n",
    "        Base_model.fit(foreground)\n",
    "        pred_f = Base_model.predict(X)\n",
    "        Base_model.fit(background)\n",
    "        pred_b = Base_model.predict(X)\n",
    "        l = len(foreground) / ( len(background) + len(foreground) )\n",
    "        pred = pred_f*l / (l*pred_f + (1-l)*pred_b)\n",
    "        scores.append(roc_auc_score(pred > threshold, y))\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB features\n",
      "Mean RGB score:  0.9447201176152941\n",
      "RGB & DoG features\n",
      "Mean DoG score: 0.9307032476121422\n",
      "MR8 features\n",
      "Mean MR8 Score: 0.8969537419208967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n",
      "/Library/Python/3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in greater\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(\"RGB features\")\n",
    "score = run(features_Train = get_RGB_train, features_Test = get_RGB_test,  threshold = 0.5, k = 6, pieces = pieces)\n",
    "print(\"Mean RGB score: \", score)\n",
    "print(\"RGB & DoG features\")\n",
    "score = run(features_Train = get_DoG_train, features_Test = get_DoG_test,  threshold = 0.5, k = 6, pieces = pieces)\n",
    "print(\"Mean DoG score:\", score)\n",
    "print(\"MR8 features\")\n",
    "score = run(features_Train = get_MR8_train, features_Test = get_MR8_test,  threshold = 0.5, k = 6, pieces = pieces)\n",
    "print(\"Mean MR8 Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
